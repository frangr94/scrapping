{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se busca en https://www.megatone.net/search/Escritorio Notebook 3045-Coe O Tables/ en fecha y hora: 2023-06-18 17:56:23.291120\n",
      "['Escritorio Notebook 3045-Coe O Tables', '$42,999', '$36,999', '2023-06-18 17:56:23.291120', 'megatone']\n",
      "data scrapeada\n",
      "se busca en https://www.fravega.com/l/?keyword=Mouse+Genius+Nx+7010+Blueeye+White/red+(new+Package)+(8629)+Genius en fecha y hora: 2023-06-18 17:56:23.291120\n",
      "['Mouse Genius Nx 7010 Blueeye White/blue (new Package) (8612) Genius', '$13.861', '9', '$12.601', '2023-06-18 17:56:23.291120', 'fravega']\n",
      "['Mouse Genius Nx-7010 Blueeye Magenta (new Package) (8636) Genius', '$13.861', '9', '$12.601', '2023-06-18 17:56:23.291120', 'fravega']\n",
      "['Mouse Genius Nx 7010 Blueeye White/red (new Package) (8629) Genius', '$13.867', '9', '$12.607', '2023-06-18 17:56:23.291120', 'fravega']\n",
      "no hay overlay\n",
      "no se encontro el item\n",
      "data scrapeada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "opt =  webdriver.ChromeOptions()\n",
    "opt.add_argument('--start-maximized')\n",
    "opt.add_argument('--disable-extensions')\n",
    "\n",
    "\n",
    "driver_path = r'/home/frangr94/Desktop/proyecto_scrapper/webdriver/chromedriver.exe'\n",
    "driver = webdriver.Chrome(options=opt)\n",
    "\n",
    "# inicializar navegador y cargar página completa, espefificar día y hora\n",
    "date_time = str(datetime.datetime.now())\n",
    "\n",
    "import pandas as pd\n",
    "productos = pd.read_csv('productos.csv')\n",
    "\n",
    "\n",
    "# funcion de scrapping\n",
    "def scrap_page(url,art,store):\n",
    "    store=store\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    print(\"se busca en\",url,\"en fecha y hora:\",date_time)\n",
    "    art=art\n",
    "\n",
    "\n",
    "    # scrapear data scaneando todas las páginas (especificar rango)\n",
    "    if store=='megatone':\n",
    "        itemlist = []\n",
    "        data=[]\n",
    "        for i in range (100):\n",
    "            page=i+2\n",
    "            items = driver.find_elements(By.CSS_SELECTOR,'div.w100.dIB.AnchoInterno.TextDeco.pR')\n",
    "\n",
    "            for i in range(len(items)):\n",
    "                itemlist.append(items[i].text)\n",
    "            itemlist = list(filter(None,itemlist))\n",
    "            arrayitems=[]\n",
    "            for i in range (len(itemlist)):\n",
    "        \n",
    "                words=str(itemlist[i]).split('\\n')\n",
    "                words=[x for x in words if 'Sin Interés' not in x]\n",
    "                words=[x for x in words if 'OFF' not in x]\n",
    "                words=[x for x in words if 'Envío' not in x]\n",
    "                words=[x for x in words if 'Ahorrá' not in x]\n",
    "                words=[x for x in words if '%' not in x]\n",
    "                words=[x for x in words if 'Hasta' not in x]\n",
    "                words=[x for x in words if 'GRATIS' not in x]\n",
    "                if len(words)<3:\n",
    "                    words.append('null')\n",
    "                words.append(date_time)\n",
    "                words.append(store)\n",
    "                print(words)\n",
    "                data.append(words)\n",
    "\n",
    "\n",
    "            try:\n",
    "                driver.execute_script(\"window.scrollBy(0,2300)\")\n",
    "                nextpage = driver.find_element(By.XPATH, '//*[@id=\"botones\"]/button[{}]'.format(page))\n",
    "                time.sleep(2)\n",
    "                nextpage.click()\n",
    "                time.sleep(2)\n",
    "            \n",
    "            except:\n",
    "                print('data scrapeada')\n",
    "                break\n",
    "\n",
    "        return data\n",
    "\n",
    "    elif store=='coppel':\n",
    "        itemlist = []\n",
    "        data=[]\n",
    "        for i in range(10):\n",
    "            page=i+1\n",
    "            driver.execute_script(\"window.scrollBy(0,50)\")\n",
    "            time.sleep(2)\n",
    "\n",
    "            items = driver.find_elements(By.CSS_SELECTOR,'.vtex-product-summary-2-x-element')\n",
    "\n",
    "            for i in range(len(items)):\n",
    "                itemlist.append(items[i].text)\n",
    "            itemlist = list(filter(None,itemlist))\n",
    "            arrayitems=[]\n",
    "            for i in range (len(itemlist)):\n",
    "        \n",
    "                words=str(itemlist[i]).split('\\n')\n",
    "                words=[x for x in words if 'Sin Interés' not in x]\n",
    "                words=[x for x in words if 'OFF' not in x]\n",
    "                words=[x for x in words if 'Envío' not in x]\n",
    "                words=[x for x in words if 'Ahorrá' not in x]\n",
    "                words=[x for x in words if '%' not in x]\n",
    "                words=[x for x in words if 'Hasta' not in x]\n",
    "                if len(words)<3:\n",
    "                    words.append('null')\n",
    "                words.append(date_time)\n",
    "                words.append(store)\n",
    "                print(words)\n",
    "                data.append(words)\n",
    "\n",
    "            \n",
    "\n",
    "            try:\n",
    "                driver.get(url+'&page={}'.format(page+1))\n",
    "                time.sleep(5)            \n",
    "            except:\n",
    "                print('data scrapeada')\n",
    "                break\n",
    "        return data\n",
    "    \n",
    "    elif store=='fravega':\n",
    "\n",
    "        data=[]\n",
    "        time.sleep(2)\n",
    "        close = driver.find_element(By.XPATH, '//*[@id=\"modal\"]/div[1]/button')\n",
    "        close.click()\n",
    "        for i in range(10):\n",
    "            page=i+1\n",
    "            items=[]\n",
    "            for i in range(63):\n",
    "                try:\n",
    "                    item = driver.find_elements(By.XPATH,'//*[@id=\"__next\"]/div[2]/div[1]/div[3]/div[5]/ul/li[{}]'.format(i+1))\n",
    "                    items.append(item)\n",
    "\n",
    "\n",
    "                except:\n",
    "                    print('no se encontro el item')\n",
    "                    break\n",
    "                    \n",
    "            listael=[]\n",
    "            for i in items:\n",
    "                for z in i:\n",
    "                    v=z.text\n",
    "                    listael.append(v)\n",
    "\n",
    "            prods=[]\n",
    "            for i in listael:\n",
    "                words=i.split('''\\n''')\n",
    "                words=[x for x in words if '¡Retiralo YA!' not in x]\n",
    "                words=[x for x in words if 'Comparar' not in x]\n",
    "                words=[x for x in words if 'Llega GRATIS en 48hs' not in x]\n",
    "                words=[x for x in words if 'Llega en 48hs' not in x]\n",
    "                words=[x for x in words if 'Retiro en 48hs' not in x]\n",
    "                words=[x for x in words if 'Envío GRATIS' not in x]\n",
    "                words=[x for x in words if 'Llega GRATIS mañana' not in x]\n",
    "                if len(words)<3:\n",
    "                    words.append('null')\n",
    "                words.append(date_time)\n",
    "                words.append(store)\n",
    "                print(words)\n",
    "                prods.append(words)\n",
    "\n",
    "\n",
    "            for i in prods:\n",
    "                item=[]\n",
    "                for z in i:\n",
    "                    try:\n",
    "                        int(z)/2\n",
    "                    except:\n",
    "                        item.append(z)\n",
    "                data.append(item)\n",
    "\n",
    "            try:\n",
    "                driver.get(url+'&page={}'.format(page+1))\n",
    "                time.sleep(5)\n",
    "            \n",
    "            except:\n",
    "                print('data scrapeada')\n",
    "                break\n",
    "            try:\n",
    "                time.sleep(2)\n",
    "                close = driver.find_element(By.XPATH, '//*[@id=\"modal\"]/div[1]/button')\n",
    "                close.click()\n",
    "            except:\n",
    "                print('no hay overlay')\n",
    "        return data\n",
    "\n",
    "\n",
    " \n",
    "# scrapear\n",
    "for i in range(len(productos)):\n",
    "    pars=(productos.loc[i,:].values.flatten().tolist())\n",
    "    if pars[1]==\"megatone\":\n",
    "        scrappage='https://www.megatone.net/search/{}/'.format(pars[0])\n",
    "        megatone_data=scrap_page(scrappage,art=pars[0],store='megatone')\n",
    "\n",
    "    elif pars[1]==\"coppel\":\n",
    "        scrappage='https://www.coppel.com.ar/{}?_q={}&map=ft'.format(pars[0],pars[0])\n",
    "        coppel_data=scrap_page(scrappage,art=pars[0],store='coppel')\n",
    "        \n",
    "    elif pars[1]==\"fravega\":\n",
    "        scrappage='https://www.fravega.com/l/?keyword={}'.format(pars[0]).replace(' ','+')\n",
    "        fravega_data=scrap_page(scrappage,art=pars[0],store='fravega')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in coppel_data:\n",
    "    data.append(i)\n",
    "\n",
    "for i in megatone_data:\n",
    "    data.append(i)\n",
    "\n",
    "for i in fravega_data:\n",
    "    data.append(i)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "fields = ['producto','precio','precio_rebaja','date_time','tienda']\n",
    "\n",
    "with open('data.csv','w',newline='') as f:\n",
    "    writer = csv.writer(f,delimiter='#')\n",
    "    writer.writerow(fields)\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora hay que crear un entorno en airflow y probarlo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
