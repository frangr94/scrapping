{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "opt =  webdriver.ChromeOptions()\n",
    "opt.add_argument('--start-maximized')\n",
    "opt.add_argument('--disable-extensions')\n",
    "\n",
    "\n",
    "driver_path = r'/home/frangr94/Desktop/proyecto_scrapper/webdriver/chromedriver.exe'\n",
    "driver = webdriver.Chrome(options=opt)\n",
    "\n",
    "# inicializar navegador y cargar página completa, espefificar día y hora\n",
    "date_time = str(datetime.datetime.now())\n",
    "megatonetienda='https://www.megatone.net/search/{}/'\n",
    "articulo=['auriculares','notebooks','lavado']\n",
    "\n",
    "import pandas as pd\n",
    "productos = pd.read_csv('productos.csv')\n",
    "\n",
    "\n",
    "\n",
    "def scrap_page(url,art):\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "    print(\"se busca en\",url,\"en fecha y hora:\",date_time)\n",
    "    art=art\n",
    "\n",
    "\n",
    "    # scrapear data scaneando todas las páginas (especificar rango)\n",
    "    itemlist = []\n",
    "    data=[]\n",
    "    for i in range (100):\n",
    "        page=i+1\n",
    "        items = driver.find_elements(By.CSS_SELECTOR,'div.w100.dIB.AnchoInterno.TextDeco.pR')\n",
    "        for i in range(len(items)):\n",
    "            itemlist.append(items[i].text)\n",
    "        itemlist = list(filter(None,itemlist))\n",
    "        arrayitems=[]\n",
    "        for i in range (len(itemlist)):\n",
    "       \n",
    "            words=str(itemlist[i]).split('\\n')\n",
    "            words=[x for x in words if 'Sin Interés' not in x]\n",
    "            words=[x for x in words if 'OFF' not in x]\n",
    "            words=[x for x in words if 'Envío' not in x]\n",
    "            words=[x for x in words if 'GRATIS' not in x]\n",
    "            if len(words)<3:\n",
    "                words.append('null')\n",
    "            words.append(date_time)\n",
    "            words.append(art)\n",
    "            print(words)\n",
    "\n",
    "            data.append(words)\n",
    "            \n",
    "        \n",
    "\n",
    "        #driver.execute_script(\"window.scrollBy(0,3500)\")\n",
    "        try:\n",
    "            nextpage = driver.find_element(By.XPATH, '//*[@id=\"botones\"]/button[{}]'.format(page))\n",
    "            #actions= ActionChains(driver)\n",
    "            #actions.move_to_element(nextpage).perform\n",
    "            driver.execute_script(\"window.scrollBy(0,2300)\")\n",
    "            time.sleep(2)\n",
    "            nextpage.click()\n",
    "            time.sleep(2)\n",
    "        \n",
    "        except:\n",
    "            print('ya esta')\n",
    "            return data\n",
    "            break\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(productos)):\n",
    "    print('esta es la iteracion numero',i+1)\n",
    "    pars=(productos.loc[i,:].values.flatten().tolist())\n",
    "    if pars[1]==\"megatone\":\n",
    "        scrappage='https://www.megatone.net/search/{}/'.format(pars[0])\n",
    "        scrap_page(scrappage,art=pars[0])\n",
    "    elif pars[1]==\"coppel\":\n",
    "        scrappage='https://www.coppel.com.ar/{}?_q={}&map=ft'.format(pars[0],pars[0])\n",
    "        scrap_page(scrappage,art=pars[0])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
